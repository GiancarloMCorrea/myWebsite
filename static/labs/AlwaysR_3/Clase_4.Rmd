---
title: "AlwaysR, Módulo III: Estadística en R"
author: "Giancarlo M. Correa"
institute: "Cousteau Consultant Group"
date: "17/07/2021"
output:
  xaringan::moon_reader:
    seal: false
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

class: inverse, center, middle

# AlwaysR, Módulo III: Estadística en R

## Clase 4: Modelos lineales II

### Giancarlo M. Correa

<img src="LOGO05.png" width="350px"/>

---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

class: inverse, center, middle

# Modelos lineales

```{r xaringan-logo, echo=FALSE}
xaringanExtra::use_logo(
  image_url = "LOGO06.png", position = xaringanExtra::css_position(bottom = '-3em', left = 0),
  link_url = 'https://cousteau-group.com/', width = "70px"
)
```

---

# Regresión múltiple: interacción

Tenemos el modelo:

$$E(Y\mid X_1, X_2) = \beta_0 + \beta_1 X_{1} +  \beta_2 X_{2}$$

En este caso $X_1$ es continua y $X_2$ es una categórica de dos niveles (0 y 1).

--

Podemos incorporar una interacción:

$$E(Y\mid X_1, X_2) = \beta_0 + \beta_1 X_{1} +  \beta_2 X_{2} + \beta_3 (X_{1}X_{2})$$

Dos variables interactúan si el efecto de una variable sobre la respuesta media depende de la otra variable.

--

$\beta_3 (X_{1}X_{2})$ es llamado el término de interacción. Permite que el efecto de $X_1$ sobre la media de $Y$ dependa en $X_2=0$ o $X_2=1$.

---

# Regresión múltiple: interacción

Cuando $X_2=0$:

$$E(Y\mid X_1, X_2) = \beta_0 + \beta_1 X_{1}$$

--

Cuando $X_2=1$:

$$E(Y\mid X_1, X_2) = \beta_0 + \beta_1 X_{1} +  \beta_2 + \beta_3 X_{1}$$

--

Estos dos modelos nos darán una línea, y estas líneas tendrán diferentes interceptos y pendientes.

---

```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(sjPlot)
library(sjmisc)
library(ggplot2)
library(faraway)
library(Sleuth3)
library(nlme)
library(olsrr)
library(lme4)
mtcars$am = factor(mtcars$am)
```

```{r}
mod1 = lm(mpg ~ cyl + am + cyl * am, data = mtcars)
summary(mod1)
```

---

```{r, out.width=500, fig.align="center"}
plot_model(mod1, type = "int")
```

---

# Regresión múltiple: interacción

Basado en el ejemplo anterior, el modelo es:

$$E(Y\mid X_1, X_2) = \beta_0 + \beta_1 X_{1} +  \beta_2 X_{2} + \beta_3 (X_{1}X_{2})$$

--

Interpretación:

- $\beta_0$: es la media de $Y$ cuando $X_1$ y $X_2$ son iguales a cero (intercepto).

--

- $\beta_1$: da el cambio en la media de $Y$ cuando $X_1$ es incrementado por una unidad y $X_2=0$.

--

- $\beta_2$: da el cambio en la media de $Y$ cuando $X_2$ cambia de 0 a 1 y $X_1$ es mantenido en cero.

--

- $\beta_3$: da la diferencia en el cambio en la media de $Y$ cuando $X_1$ es incrementado en una unidad cuando $X_2=1$, comparado al cambio en la media de $Y$ cuando $X_1$ es incrementado en una unidad cuando $X_2=0$.

---

# Problemas con datos

### Multicolinealidad

- No genera problemas estadísticos, sin embargo, genera problemas en la interpretación.

--

- No tiene sentido interpretar *el efecto de $X_1$ manteniendo otras variables independientes constante* porque nosotros hemos observado una relación entre $X_1$ y otras variables.

---

```{r}
mod2 = lm(hipcenter ~ ., data = seatpos)
summary(mod2)
```

---

# Problemas con datos

La matriz de correlación entre *todas* las variables:

```{r}
round(cor(seatpos), digits = 2)
```

---

# Problemas con datos

¿Qué podemos hacer cuando tenemos variables correlacionadas?

- Seleccionar las variables más importantes

--

- Identificar las variables correlacionadas claves para el modelo: variance inflation factors (VIF)

--

```{r}
round(vif(mod2), digits = 2)
```

Valores $VIF_j >10$ indican una alta colinealidad.

--

Eliminar algunas variables no significa que ellas no están asociadas con la variable respuesta, solo que no las necesitamos para predecir la respuesta.

---

# Datos faltantes

Podemos hablar de dos casos:

* **Caso faltante**: cuando no tenemos información de *todas* las variables en una observación en el conjunto de datos.

--

* **Valores faltantes**: cuando no tenemos información de *algunas* variables en una observación en el conjunto de datos.

--

```{r}
head(chmiss, n = 10)
```

---

# Datos faltantes

Hay dos enfoques para lidiar con esto:

- **Métodos de supresión**: eliminar las observaciones con algun tipo de datos faltantes.

--

- **Métodos de retención**: retienen las observaciones con datos faltantes para implementar una regresión modificada para datos faltantes.

--

### Método de supresión

Simplemente eliminar las observaciones con datos faltantes e implementar el modelo luego. R hace esto por nosotros automaticamente.

```{r, echo =FALSE}
head(chmiss, n = 10)
```

---

### Método de retención

- **Imputación**: completar los datos perdidos con la media de cada variable. Se puede usar también la mediana, moda, etc. *Problemas*: Introduce error. Métodos de estimación de parámetros pueden estar sesgados.

--

- **Imputación a partir de regresión**: Implementar un modelo lineal con las observaciones completas. Luego, predecir valores cuando hayan datos faltantes. En este caso, la variable respuesta será la variable que tiene datos faltantes y las variables independientes todas las demás variables. 

---

# Selección de modelos

El proceso de seleccionar tan pocas variables como sea posible para incluir en el modelo lineal (principio de parsimonia).

--

```{r}
head(case1201)
```

---

```{r}
mod3 = lm(SAT ~ Takers + Income + Years + Public + Expend + Rank, data=case1201)
summary(mod3)
```

---

# Selección de modelos

Con esta base de datos, el modelo más simple que podemos implementar es:

$$SAT_i=\beta_0+\epsilon_i$$

--

El modelo más complicado es:

$$SAT_i=\beta_0+ \beta_1 Income_i+ \beta_2 Takers_i + \beta_3 Years_i + \beta_4 Rank_i + \beta_5 Expend_i + \beta_6 Public_i + \epsilon_i$$

--

¿Cuantos modelos podemos implementar con esta base de datos?

--

$2^6$ modelos posibles! (sin considerar interacciones!)

---

# Selección de modelos

- **Eliminación hacia atrás**: Comienza con el full model. Elimina la variable con mayor *p-value* y corre el modelo nuevamente. Repite este proceso hasta que el modelo solo contiene variables con *p-value* por dejabo del valor crítico $\alpha$.

--

- **Selección hacia adelante**: Comienza con el modelo más sencillo (solo contiene intercepto). Añade la variable con menor *p-value* por debajo del nivel crítico $\alpha$. Repetir hasta que no haya variable que pueda ser añadida con *p-value* por debajo del nivel crítico $\alpha$.

--

### Limitaciones

- Inclusión en el modelo no necesariamente significa que la variable es importante. 
- Exclusión no necesariamente significa que la variable no sea importante. 
- Se tiende a elegir los modelos más pequeños que los óptimos para predicción.

---

```{r}
mod3 = lm(SAT ~ Takers + Income + Years + Public + Expend + Rank, data=case1201)
backmod = ols_step_backward_p(mod3, prem=0.05, progress=FALSE) # Seleccion hacia atras
summary(backmod$model)
```


---

```{r}
mod3 = lm(SAT ~ Takers + Income + Years + Public + Expend + Rank, data=case1201)
forwardmod = ols_step_forward_p(mod3, penter=0.05, progress=FALSE) # Seleccion hacia adelante
summary(forwardmod$model)
```

---

# Selección de modelos

Métodos basados en criterio:

- $AIC$: Criterio de información de Akaike. Toma en cuenta el número de observaciones, parámetros, y suma de residuales. Normalmente el menor $AIC$ nos indica un mejor modelo.

- $BIC$: Criterio de información Bayesiana. Toma en cuenta el número de observaciones, parámetros, y suma de residuales. Normalmente el menor $BIC$ nos indica un mejor modelo.

- $R^2-adj$: El mayor valor nos indica el mejor modelo.

--

Si deseas obtener el mejor modelo, se recomienda usar $BIC$.

Si deseas usar el modelo para hacer predicciones, se recomienda usar $AIC$.

Los modelos no necesitan ser anidados para ser comparados (pero si deben contener los mismos datos).

---

```{r}
mod4 = lm(SAT ~ Years + Expend + Rank, data=case1201)
summ4 = summary(mod4)
mod5 = lm(SAT ~ Income + Years + Expend + Rank, data=case1201)
summ5 = summary(mod5)
```

Comparar modelos con $R^2-adj$:

```{r}
summ4$adj.r.squared
summ5$adj.r.squared
```

---

Comparar modelos con $AIC$:

```{r}
AIC(mod4)
AIC(mod5)
```

--

Comparar modelos con $BIC$:

```{r}
BIC(mod4)
BIC(mod5)
```

---

# Problemas con supuestos

--

### Linealidad de la asociación

- Consecuencia depende en el grado de no-linealidad.

- Buscar alternativas (e.g. modelos aditivos generalizados, splines, etc.)

--

### Independencia

- Un modelo lineal no es robusto a la no independencia de observaciones.

- Alternativa, usar la función `gls` (siempre y cuando se conozca la estructura del error)

---

```{r}
head(globwarm)
```

---

```{r, out.width=500, fig.align="center"}
lmod = lm(nhtemp ~ wusa + jasper + westgreen + chesapeake + tornetrask + urals + mongolia + tasman, data=globwarm)
plot(lmod$residuals)
```

---

```{r}
glmod = gls(nhtemp ~ wusa + jasper + westgreen + chesapeake +
                tornetrask + urals + mongolia + tasman,
                correlation=corAR1(form=~year),
                data=na.omit(globwarm),
                method="ML")
print(glmod)
```

---

# Problemas con supuestos

### Normalidad

- Si se tiene un muestreo grande $n$, este supuesto no causa problemas importantes.

- Se recomienda usar ejercicios de simulación para saber los efectos de la no-normalidad de residuos sobre los parámetros estimados.

---

# Problemas con supuestos

### Normalidad

```{r echo = FALSE, out.width=600, fig.align="center"}
knitr::include_graphics("images/fig24.png")
```

---

# Problemas con supuestos

### Normalidad

```{r echo = FALSE, out.width=600, fig.align="center"}
knitr::include_graphics("images/fig25.png")
```

---

# Transformaciones

Pueden ayudar en el ajuste del modelo y cumplir los supuestos de la regresión lineal (e.g. supuesto de varianza constante).

--

En vez de $Y_i = \beta_0+\beta_1 X_i + \epsilon_i$, podemos escribir:

$$log(Y_i) = \beta_0 + \beta_1 X_i + \epsilon_i$$

--

Despues de ajustar el modelo, tenemos que volver a la escala original:

$$Y_i = exp(\beta_0 + \beta_1 X_i)exp(\epsilon_i)$$

--

Obtener la variable respuesta en su escala original no es muy complicado. Sin embargo, los coeficientes estimados ya no tienen la misma interpretación. Por ejemplo:

- Un incremento en una unidad en $X_1$ ahora multiplicaría la respuesta media (en su escala original) por $e^{\hat{\beta_1}}$.

---

```{r}
head(gala)
```

---

```{r , out.width=500, fig.align="center"}
lmod = lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, data=gala)
plot(lmod, which=1)
```

---

```{r , out.width=500, fig.align="center"}
gala$logSpecies = log(gala$Species)
lmod = lm(logSpecies ~ Area + Elevation + Nearest + Scruz + Adjacent, data=gala)
plot(lmod, which=1)
```

---

# Efectos aleatorios

- Modelo de efectos mixtos: cuando tenemos efectos fijos (como hemos visto hasta el momento) y efectos mixtos (como describiremos aquí).

--

- **Efecto fijo**: Se asume que no hay relación entre los diferentes niveles de una variable. Ejemplo: un efecto para hembras y un efecto para machos, pero estos efectos no interactúan uno con el otro.

--

- **Efecto aleatorio**: Nos da información acerca de niveles específicos (similar a un efecto fijo), pero también a nivel poblacional. Los niveles o grupos en un efecto aleatorio puede ser pensado como una muestra de niveles de una población más grande de niveles.

--

Tomar en cuenta:

- No usar efectos aleatorios cuando el número de niveles es bajo.
- No usar efectos aleatorios cuando no se quiere asumir que estos niveles vienen de una distribución común en la población.

---

# Efectos aleatorios

¿En qué casos debo incorporar efectos aleatorios?

1. ¿Los factores pueden ser considerados como una muestra aleatoria de una distribución de probabilidad?

2. ¿La investigación tiene por objetivo hacer inferencia a una población mayor a la incluida en el modelo?

3. ¿Hay una falta de independencia estadística debido a múltiples observaciones para un mismo nivel?

---

# Efectos aleatorios

```{r echo = FALSE, out.width=600, fig.align="center"}
knitr::include_graphics("images/fig26.png")
```

---

# Efectos aleatorios

```{r}
head(sleepstudy)
```

---

Un modelo con efecto aleatorio en el intercepto:

```{r}
lmod1 = lmer ( Reaction ~ Days + ( 1 | Subject ) , data= sleepstudy )
summary(lmod1)
```

---

Un modelo con efecto aleatorio en el intercepto:

```{r}
coef(lmod1)$Subject
```


---

Un modelo con efecto aleatorio en la pendiente:

```{r}
lmod2 = lmer ( Reaction ~ Days + ( 0 + Days | Subject ) , data= sleepstudy )
summary(lmod2)
```

---

Un modelo con efecto aleatorio en la pendiente:

```{r}
coef(lmod2)$Subject
```

---

Un modelo con efecto aleatorio en el intercepto y la pendiente:

```{r}
lmod3 = lmer ( Reaction ~ Days + ( Days | Subject ) , data= sleepstudy )
summary(lmod3)
```

---

Un modelo con efecto aleatorio en el intercepto y la pendiente:

```{r}
coef(lmod3)$Subject
```

---

class: inverse, center, middle

# Gracias!

Contacto: [**cursos@cousteau-group.com**](mailto:cursos@cousteau-group.com)

```{r echo = FALSE, out.width=450, fig.align="center"}
knitr::include_graphics("LOGO05.png")
```
